{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40780a97",
   "metadata": {},
   "source": [
    "# Basic Planning\n",
    "\n",
    "\n",
    "* We have roughly ~11k images with faces detected using the YOLO model. Now, the goal of this is to filter the dataset so that we can get a few faces with decent base resolution for the face generation training.\n",
    "* Since we are generating the face to be around 128x128 pixels, we can see how many faces directly fall into this category. If the number is insufficient (or) small, then we can check for the faces larger than 64x64 pixels and then resize them to 128x128 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "964a58ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11316/11316 [00:14<00:00, 796.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces with size >= 128x128: 4309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "image_dir = \"test_images\"\n",
    "bbox_dir = \"inference_results\" #inference results from YOLO\n",
    "\n",
    "def filter_128_faces(image_name):\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    bbox_path = os.path.join(bbox_dir, image_name.replace('.jpg', '.txt'))\n",
    "\n",
    "    if not os.path.exists(bbox_path):\n",
    "        return False\n",
    "\n",
    "    with open(bbox_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    os.makedirs(\"filtered_faces_128\", exist_ok=True)\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        x1, y1, w, h = map(float, parts[2:6])\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        \n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "\n",
    "        if width*height >= 128*128:\n",
    "            image = Image.open(image_path)\n",
    "            face = image.crop((x1, y1, x2, y2))\n",
    "            face = face.resize((128, 128))\n",
    "            face.save(os.path.join(\"filtered_faces_128\", image_name))\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "remaining_images=[]\n",
    "\n",
    "for img in tqdm(images):\n",
    "    filtered = filter_128_faces(img)\n",
    "    if not filtered:\n",
    "        remaining_images+=[img]\n",
    "\n",
    "number_of_faces = len(os.listdir(\"filtered_faces_128\"))\n",
    "print(f\"Number of faces with size >= 128x128: {number_of_faces}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_transforms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
